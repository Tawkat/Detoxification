{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d638599-299e-4d48-9e23-0d5fb3e50a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "datasets_list = os.listdir('Generated_Data/DataFrame/')\n",
    "\n",
    "\n",
    "#datasets_list = ['combined_binary_en_HateCheck.csv','combined_binary_en_yt_reddit.csv', 'EN_combined_binary.csv',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b510b42-c45a-4093-88ed-1d76a1a9f72a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "      <th>binary_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The reason you see Indians bashing Muslims and...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Why don't they have their own games?</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fuck bulgaria stupid country</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Finally someone who means what he says. It's ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Who do you think you are cunt? wtf! Stay stead...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  labels  binary_labels\n",
       "0  The reason you see Indians bashing Muslims and...     1.0              1\n",
       "1               Why don't they have their own games?     0.0              0\n",
       "2                       fuck bulgaria stupid country     1.0              1\n",
       "3  Finally someone who means what he says. It's ...     0.0              0\n",
       "4  Who do you think you are cunt? wtf! Stay stead...     1.0              1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind = 4\n",
    "df = pd.read_csv(f'Datasets/{datasets_list[ind]}')\n",
    "df = df.dropna(subset=['text','binary_labels'])\n",
    "df = df.reset_index(drop=True,inplace=False)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a70e665f-2930-428a-b926-6b10e32a7f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_classifiers = {}\n",
    "classifiers = ['HateCheck', 'stormfront', 'twitter', 'fb_yt', 'convAI','wikipedia']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dce8687a-3353-41e9-a36e-1d528df5b34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "for model in classifiers:\n",
    "    df_classifiers[model] = pipeline('text-classification', model=f'Output_Dir/{model}', device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7cbbdc34-9c20-44d9-978b-e48c3c5f9da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "model = pipeline('text-classification', model=f'Output_Dir/{classifiers[4]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85a6402d-8265-4b30-aeeb-e1cc92ea5501",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 0, 'score': 0.9990739822387695},\n",
       " {'label': 0, 'score': 0.9988235831260681}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(['Hello','Hi'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac55a91-e4ac-47d0-a635-ff9dad18e2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "cnt = 4\n",
    "for dataset in tqdm(datasets_list):\n",
    "    if(not dataset.endswith('.csv')):\n",
    "        continue\n",
    "    df_data = pd.read_csv(f'Generated_Data/DataFrame/{dataset}')\n",
    "    \n",
    "    df_new = {}\n",
    "    for col in df_data.columns:\n",
    "        df_new[col] = []\n",
    "    df_new['toxic_count'] = []\n",
    "    df_new['non_toxic_count'] = []\n",
    "    for c in classifiers:\n",
    "        df_new[c] = []\n",
    "    \n",
    "    toxic_list = []\n",
    "    non_toxic_list = []\n",
    "    for ind in range(len(df_data['data_id'])):\n",
    "        if(df_data['source_label'][ind]=='toxic'):\n",
    "            toxic_list.append(df_data['source_text'][ind])\n",
    "            non_toxic_list.append(df_data['target_text'][ind])\n",
    "        else:\n",
    "            non_toxic_list.append(df_data['source_text'][ind])\n",
    "            toxic_list.append(df_data['target_text'][ind])\n",
    "        \n",
    "\n",
    "        for col in df_data.columns:\n",
    "            df_new[col].append(df_data[col][ind])\n",
    "\n",
    "    tmp_data = {}\n",
    "\n",
    "\n",
    "    for model in classifiers:\n",
    "        tmp_data[f'toxic_{model}'] = df_classifiers[model](toxic_list, max_length = 512, \n",
    "                                                           padding = 'max_length', truncation=True)\n",
    "        tmp_data[f'non_toxic_{model}'] = df_classifiers[model](non_toxic_list, max_length = 512,\n",
    "                                                               padding = 'max_length', truncation=True)\n",
    "\n",
    "    for k in range(len(df_data['source_text'])): #zip(tmp_data[f'toxic_{model}'],tmp_data[f'non_toxic_{model}']):\n",
    "        tox_cnt = non_tox_cnt = 0\n",
    "        for model in classifiers:\n",
    "            tox = tmp_data[f'toxic_{model}'][k]['label']\n",
    "            non_tox = tmp_data[f'non_toxic_{model}'][k]['label']\n",
    "            df_new[model].append(f'{tox}_{non_tox}')\n",
    "            tox_cnt+= int(tox)\n",
    "            non_tox_cnt += int(non_tox)\n",
    "\n",
    "        df_new['toxic_count'].append(tox_cnt)\n",
    "        df_new['non_toxic_count'].append(non_tox_cnt)   \n",
    "\n",
    "    \n",
    "\n",
    "    df_new = pd.DataFrame(df_new)\n",
    "    df_new.to_csv(f'Generated_Data/Pred_DataFrame/{dataset}',index=False)\n",
    "        \n",
    "        #print(f'Dataset: {dataset} ## Original Length:{len(df_data['source_text'])} ## New ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ed627c-282e-457f-baa8-2725e95be165",
   "metadata": {},
   "outputs": [],
   "source": [
    "!./run_python_refine_1.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07969f65-4aa3-4ade-879d-e8208fd6f946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hatecheck_3000.csv: Original: 2741 ## Modified: 1398\n",
      "twitter and facebook_3000.csv: Original: 3000 ## Modified: 1749\n",
      "wikipedia_3000.csv: Original: 2995 ## Modified: 2153\n",
      "twitter_3000.csv: Original: 3000 ## Modified: 2337\n",
      "convai_3000.csv: Original: 650 ## Modified: 552\n",
      "fb_yt_3000.csv: Original: 2897 ## Modified: 1901\n",
      "yt_reddit_3000.csv: Original: 222 ## Modified: 156\n",
      "fox news_3000.csv: Original: 1104 ## Modified: 831\n",
      "stormfront_3000.csv: Original: 3000 ## Modified: 2511\n",
      "gab_3000.csv: Original: 3000 ## Modified: 2151\n",
      "reddit_3000.csv: Original: 3000 ## Modified: 2222\n",
      "TOTAL Ori: 25609 ### TOTAL Modified: 17961\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "file_list = os.listdir('Generated_Data/Pred_3K_DataFrame')\n",
    "\n",
    "total_ori = 0\n",
    "total_new = 0\n",
    "\n",
    "for file in file_list:\n",
    "    if(not file.endswith('.csv')):\n",
    "        continue\n",
    "    df_ori = pd.read_csv(f'Generated_Data/Pred_3K_DataFrame/{file}')\n",
    "    df_new = df_ori[(df_ori['toxic_count']>0) & (df_ori['non_toxic_count']<1)]\n",
    "    \n",
    "    print(f\"{file}: Original: {len(df_ori['source_text'])} ## Modified: {len(df_new['source_text'])}\")\n",
    "    total_ori += len(df_ori['source_text'])\n",
    "    total_new += len(df_new['source_text'])\n",
    "    \n",
    "print(f\"TOTAL Ori: {total_ori} ### TOTAL Modified: {total_new}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531144cb-1400-4e98-90d0-65d6d7a2ecb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREATE DATASET FOR FINETUNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b19077a-3119-4599-88e6-c4f8c92cb2a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:00<00:00, 20.53it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "file_list = os.listdir('Datasets/Coverted_Col_Name_3K')\n",
    "\n",
    "df_train_all = pd.DataFrame()\n",
    "df_val_all = pd.DataFrame()\n",
    "df_test_all = pd.DataFrame()\n",
    "\n",
    "for file in tqdm(file_list):\n",
    "    if(not file.endswith('.csv')):\n",
    "        continue\n",
    "    df_ori = pd.read_csv(f'Datasets/Coverted_Col_Name_3K/{file}')\n",
    "    df_new = df_ori[(df_ori['toxic_count']>0) & (df_ori['non_toxic_count']<1)]\n",
    "    \n",
    "    TEST_SIZE = 100\n",
    "    if(file.startswith('yt_reddit')):\n",
    "        TEST_SIZE = 50\n",
    "    \n",
    "    df_train_val, df_test = train_test_split(df_new, test_size=TEST_SIZE)\n",
    "    df_train, df_val = train_test_split(df_train_val, test_size=TEST_SIZE)\n",
    "    \n",
    "    df_train_all = pd.concat([df_train_all,df_train], ignore_index=True)\n",
    "    df_val_all = pd.concat([df_val_all,df_val], ignore_index=True)\n",
    "    df_test_all = pd.concat([df_test_all,df_test], ignore_index=True)\n",
    "\n",
    "\n",
    "for i in range(5):\n",
    "    df_train_all = shuffle(df_train_all)\n",
    "    df_train_all = df_train_all.reset_index(inplace=False, drop=True)\n",
    "    df_val_all = shuffle(df_val_all)\n",
    "    df_val_all = df_val_all.reset_index(inplace=False, drop=True)\n",
    "    df_test_all = shuffle(df_test_all)\n",
    "    df_test_all = df_test_all.reset_index(inplace=False, drop=True)\n",
    "\n",
    "\n",
    "#print(f\"{file}: Original: {len(df_ori['source_text'])} ## Modified: {len(df_new['source_text'])}\")\n",
    "df_train_all.to_csv('Datasets/Toxicity_All_Platform_3K/train/train_All_Platform_3K.csv', index=False)\n",
    "df_val_all.to_csv('Datasets/Toxicity_All_Platform_3K/validation/val_All_Platform_3K.csv', index=False)\n",
    "df_test_all.to_csv('Datasets/Toxicity_All_Platform_3K/test/test_All_Platform_3K.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b464a7b-901f-486c-b189-12c5806b9cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 3/12 [00:00<00:00, 15.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1398\n",
      "1298\n",
      "1749\n",
      "1649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 5/12 [00:00<00:00,  7.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2153\n",
      "2053\n",
      "2337\n",
      "2237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 7/12 [00:00<00:00,  7.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "552\n",
      "452\n",
      "1901\n",
      "1801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 9/12 [00:00<00:00,  9.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156\n",
      "106\n",
      "831\n",
      "731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 11/12 [00:01<00:00,  7.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2511\n",
      "2411\n",
      "2151\n",
      "2051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:01<00:00,  7.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2222\n",
      "2122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "file_list = os.listdir('Datasets/Coverted_Col_Name_3K')\n",
    "\n",
    "df_train_all = pd.DataFrame()\n",
    "df_val_all = pd.DataFrame()\n",
    "df_test_all = pd.read_csv('Datasets/Toxicity_All_Platform_3K/test/test_All_Platform_3K.csv')\n",
    "\n",
    "\n",
    "for file in tqdm(file_list):\n",
    "    if(not file.endswith('.csv')):\n",
    "        continue\n",
    "    df_ori = pd.read_csv(f'Datasets/Coverted_Col_Name_3K/{file}')\n",
    "    df_new = df_ori[(df_ori['toxic_count']>0) & (df_ori['non_toxic_count']<1)]\n",
    "    print(len(df_new['data_id']))\n",
    "    id_list = df_test_all['data_id'].tolist()\n",
    "    df_new = df_new[df_new['data_id'].isin(id_list)==False]\n",
    "    print(len(df_new['data_id']))\n",
    "    \n",
    "    \n",
    "    TEST_SIZE = 100\n",
    "    if(file.startswith('yt_reddit')):\n",
    "        TEST_SIZE = 50\n",
    "    \n",
    "    df_train, df_val = train_test_split(df_new, test_size=TEST_SIZE)\n",
    "    #df_train, df_val = train_test_split(df_train_val, test_size=TEST_SIZE)\n",
    "    \n",
    "    df_train_all = pd.concat([df_train_all,df_train], ignore_index=True)\n",
    "    df_val_all = pd.concat([df_val_all,df_val], ignore_index=True)\n",
    "    #df_test_all = pd.concat([df_test_all,df_test], ignore_index=True)\n",
    "\n",
    "\n",
    "for i in range(5):\n",
    "    df_train_all = shuffle(df_train_all)\n",
    "    df_train_all = df_train_all.reset_index(inplace=False, drop=True)\n",
    "    df_val_all = shuffle(df_val_all)\n",
    "    df_val_all = df_val_all.reset_index(inplace=False, drop=True)\n",
    "    #df_test_all = shuffle(df_test_all)\n",
    "    #df_test_all = df_test_all.reset_index(inplace=False, drop=True)\n",
    "\n",
    "\n",
    "#print(f\"{file}: Original: {len(df_ori['source_text'])} ## Modified: {len(df_new['source_text'])}\")\n",
    "df_train_all.to_csv('Datasets/Toxicity_All_Platform_3K/train/train_All_Platform_3K.csv', index=False)\n",
    "df_val_all.to_csv('Datasets/Toxicity_All_Platform_3K/validation/val_All_Platform_3K.csv', index=False)\n",
    "#df_test_all.to_csv('Datasets/Toxicity_All_Platform_3K/test/test_All_Platform_3K.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3fd619-9106-4273-b0bb-a9286888308d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREATE DATASET FOR PLATFORM-SPECIFIC FINETUNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8fb8f723-d74c-4431-a770-b0c76bd23ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:00<00:00, 27.26it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "#from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "SPLIT = {\n",
    "    'train': ['wikipedia', 'reddit', 'twitter and facebook', 'twitter'],\n",
    "    'validation': ['yt_reddit','fb_yt'],\n",
    "    'test': ['convai', 'fox news', 'gab', 'hatecheck', 'stormfront'],\n",
    "}\n",
    "\n",
    "file_list = os.listdir('Datasets/Coverted_Col_Name_3K')\n",
    "\n",
    "df_train_all = pd.DataFrame()\n",
    "df_val_all = pd.DataFrame()\n",
    "df_test_all = pd.DataFrame()\n",
    "\n",
    "#print(SPLIT['train'])\n",
    "\n",
    "for file in tqdm(file_list):\n",
    "    #print(file.split('_1000')[0])\n",
    "    if(not file.endswith('.csv')):\n",
    "        continue\n",
    "    df_ori = pd.read_csv(f'Datasets/Coverted_Col_Name_3K/{file}')\n",
    "    df_new = df_ori[(df_ori['toxic_count']>0) & (df_ori['non_toxic_count']<1)]\n",
    "    \n",
    "    \n",
    "    if(file.split('_3000')[0] in SPLIT['train']):\n",
    "        df_train_all = pd.concat([df_train_all,df_new], ignore_index=True)\n",
    "    elif(file.split('_3000')[0] in SPLIT['validation']):\n",
    "        df_val_all = pd.concat([df_val_all,df_new], ignore_index=True)\n",
    "    elif(file.split('_3000')[0] in SPLIT['test']):\n",
    "        df_test_all = pd.concat([df_test_all,df_new], ignore_index=True)\n",
    "\n",
    "\n",
    "for i in range(5):\n",
    "    df_train_all = shuffle(df_train_all)\n",
    "    df_train_all = df_train_all.reset_index(inplace=False, drop=True)\n",
    "    df_val_all = shuffle(df_val_all)\n",
    "    df_val_all = df_val_all.reset_index(inplace=False, drop=True)\n",
    "    df_test_all = shuffle(df_test_all)\n",
    "    df_test_all = df_test_all.reset_index(inplace=False, drop=True)\n",
    "\n",
    "\n",
    "#print(f\"{file}: Original: {len(df_ori['source_text'])} ## Modified: {len(df_new['source_text'])}\")\n",
    "df_train_all.to_csv('Datasets/Toxicity_Specific_Platform_3K/train/train_Specific_Platform_3K.csv', index=False)\n",
    "df_val_all.to_csv('Datasets/Toxicity_Specific_Platform_3K/validation/val_Specific_Platform_3K.csv', index=False)\n",
    "df_test_all.to_csv('Datasets/Toxicity_Specific_Platform_3K/test/test_Specific_Platform_3K.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b80b45b8-2aaf-4b25-a57b-dd08211031a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    }
   ],
   "source": [
    "from evaluate import load\n",
    "bertscore = load(\"bertscore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "03952b9b-4f09-40b4-83c3-cad9acb4a8b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'precision': [0.9530810117721558], 'recall': [0.9530810117721558], 'f1': [0.9530810117721558], 'hashcode': 'distilbert-base-uncased_L5_no-idf_version=0.3.12(hug_trans=4.28.1)'}\n"
     ]
    }
   ],
   "source": [
    "model_type = \"princeton-nlp/sup-simcse-roberta-large\" #\"distilbert-base-uncased\"\n",
    "\n",
    "predictions = [\"All women should die\"]\n",
    "references = [\"No men should die\"]\n",
    "\n",
    "results = bertscore.compute(predictions=predictions, references=references, model_type=model_type, device=0)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a82821b-7a0a-4f8d-adac-d4929995140a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4a764a0d-3848-43e6-a7be-f557b8608c69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8734]], device='cuda:0')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "sentences = [\"All women should die\", \n",
    "             \"No women should die\"]\n",
    "\n",
    "model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
    "\n",
    "#Compute embedding for both lists\n",
    "embedding_1= model.encode(sentences[0], convert_to_tensor=True)\n",
    "embedding_2 = model.encode(sentences[1], convert_to_tensor=True)\n",
    "\n",
    "util.pytorch_cos_sim(embedding_1, embedding_2)\n",
    "## tensor([[0.6003]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec07f58-c3ae-4959-bc5d-61b8a235f5c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
