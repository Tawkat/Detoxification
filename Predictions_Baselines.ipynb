{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d3d7abb-25ad-4c8e-a511-cfeeb79e0a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0330fc52-0d90-49b3-a1fe-250cfe272106",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "with open(\"Datasets/ParaDetox/test/test_toxic_parallel.txt\", \"r\") as f:\n",
    "    sources = f.readlines()\n",
    "\n",
    "with open(\"Datasets/ParaDetox/test/test_toxic_parallel_refs.txt\", \"r\") as f:\n",
    "    references = f.readlines()\n",
    "\n",
    "df = {}\n",
    "df['toxic'] = sources\n",
    "df['non_toxic'] = references\n",
    "\n",
    "df = pd.DataFrame(df)\n",
    "\n",
    "df['index'] = df.index\n",
    "df.to_csv(\"Datasets/ParaDetox/test/ParaDetox_test.csv\", index=False, columns=['index','toxic', 'non_toxic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7034e38-57ec-418b-ad6d-27597c0ee148",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "model_name = 'SkolkovoInstitute/bart-base-detox'\n",
    "model = pipeline('text2text-generation', model=model_name, device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "393127b9-e523-425f-8ef0-1a39c893e872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'Hello'}, {'generated_text': 'All women should die'}]\n"
     ]
    }
   ],
   "source": [
    "toxic_list = [\n",
    "    \"Hello\",\n",
    "    \"All women should fucking die\",\n",
    "]\n",
    "\n",
    "response = model(toxic_list, max_length = 1024, truncation=True)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3b2aabd-d710-4da5-b5df-b80021f86bbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"columns = ['source_text', 'target_text', 'source_label', 'detox_pred', 'platform', 'source_file',\\n   'data_id', 'template', 'toxic_count', 'non_toxic_count', 'HateCheck',\\n   'stormfront', 'twitter', 'fb_yt', 'convAI', 'wikipedia',]\\n\\ndf_ori.to_csv(f'Generated_Data/Detox_Pred_DataFrame/{file}', index=False,)# columns=columns)\\n\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "df_all_test = pd.read_csv(\"Datasets/ParaDetox/test/ParaDetox_test.csv\")\n",
    "\n",
    "prefix = ''\n",
    "\n",
    "\n",
    "sources = df_all_test['toxic'].tolist()\n",
    "references = df_all_test['non_toxic'].tolist()\n",
    "\n",
    "toxic_list = []\n",
    "for ss in sources:\n",
    "    toxic_list.append(prefix+ss)\n",
    "    \n",
    "responses = model(toxic_list, max_length = 512, truncation=True)\n",
    "\n",
    "model_pred = []\n",
    "for res in responses:\n",
    "    model_pred.append(res['generated_text'])\n",
    "predictions = model_pred\n",
    "\n",
    "\n",
    "output_prediction_file = os.path.join(\"Output_Dir/ParaDetox_Test_Prediction\", \"paradetox_paradetox_predictions.jsonl\")\n",
    "\n",
    "with open(output_prediction_file, \"w\") as writer:             \n",
    "    for src, ref, pred in zip(sources, references, predictions):\n",
    "        output = {\n",
    "            'source': src,\n",
    "            'reference': ref,\n",
    "            'prediction': pred,\n",
    "        }\n",
    "        json.dump(output, writer)\n",
    "        #writer.write(\"REFERENCES: \"+str(ref))\n",
    "        #writer.write(\"\\nPREDICTION: \"+str(pred))\n",
    "        writer.write(\"\\n\")\n",
    "\n",
    "\n",
    "'''columns = ['source_text', 'target_text', 'source_label', 'detox_pred', 'platform', 'source_file',\n",
    "   'data_id', 'template', 'toxic_count', 'non_toxic_count', 'HateCheck',\n",
    "   'stormfront', 'twitter', 'fb_yt', 'convAI', 'wikipedia',]\n",
    "\n",
    "df_ori.to_csv(f'Generated_Data/Detox_Pred_DataFrame/{file}', index=False,)# columns=columns)\n",
    "'''\n",
    "#print(f\"TOTAL Ori: {total_ori} ### TOTAL Modified: {total_new}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01baf0fc-b0fc-4617-8221-aae08ba510bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "model_name = 'Output_Dir/Training_T5_1/Training_Platform_1/'\n",
    "model = pipeline('text2text-generation', model=model_name, device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c21f52bb-5bd5-4b4b-a288-a5f0f9a3232d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"columns = ['source_text', 'target_text', 'source_label', 'detox_pred', 'platform', 'source_file',\\n   'data_id', 'template', 'toxic_count', 'non_toxic_count', 'HateCheck',\\n   'stormfront', 'twitter', 'fb_yt', 'convAI', 'wikipedia',]\\n\\ndf_ori.to_csv(f'Generated_Data/Detox_Pred_DataFrame/{file}', index=False,)# columns=columns)\\n\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "df_all_test = pd.read_csv(\"Datasets/ParaDetox/test/ParaDetox_test.csv\")\n",
    "\n",
    "prefix = \"Rewrite the following toxic input into non-toxic version:\\n Input: \"\n",
    "\n",
    "\n",
    "sources = df_all_test['toxic'].tolist()\n",
    "references = df_all_test['non_toxic'].tolist()\n",
    "\n",
    "toxic_list = []\n",
    "for ss in sources:\n",
    "    toxic_list.append(prefix+ss)\n",
    "    \n",
    "responses = model(toxic_list, max_length = 512, truncation=True)\n",
    "\n",
    "model_pred = []\n",
    "for res in responses:\n",
    "    model_pred.append(res['generated_text'])\n",
    "predictions = model_pred\n",
    "\n",
    "\n",
    "output_prediction_file = os.path.join(\"Output_Dir/ParaDetox_Test_Prediction\", \"t5_prompt_paradetox_predictions.jsonl\")\n",
    "\n",
    "with open(output_prediction_file, \"w\") as writer:             \n",
    "    for src, ref, pred in zip(sources, references, predictions):\n",
    "        output = {\n",
    "            'source': src,\n",
    "            'reference': ref,\n",
    "            'prediction': pred,\n",
    "        }\n",
    "        json.dump(output, writer)\n",
    "        #writer.write(\"REFERENCES: \"+str(ref))\n",
    "        #writer.write(\"\\nPREDICTION: \"+str(pred))\n",
    "        writer.write(\"\\n\")\n",
    "\n",
    "\n",
    "'''columns = ['source_text', 'target_text', 'source_label', 'detox_pred', 'platform', 'source_file',\n",
    "   'data_id', 'template', 'toxic_count', 'non_toxic_count', 'HateCheck',\n",
    "   'stormfront', 'twitter', 'fb_yt', 'convAI', 'wikipedia',]\n",
    "\n",
    "df_ori.to_csv(f'Generated_Data/Detox_Pred_DataFrame/{file}', index=False,)# columns=columns)\n",
    "'''\n",
    "#print(f\"TOTAL Ori: {total_ori} ### TOTAL Modified: {total_new}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0b0b1e2-5dcc-40d8-b978-a99abd7fd1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "model_name = 'Output_Dir/Training_T5_Prefix_1/Training_Platform_1/'\n",
    "model = pipeline('text2text-generation', model=model_name, device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57d4b0b6-a2de-4959-b5e9-463a984cddf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"columns = ['source_text', 'target_text', 'source_label', 'detox_pred', 'platform', 'source_file',\\n   'data_id', 'template', 'toxic_count', 'non_toxic_count', 'HateCheck',\\n   'stormfront', 'twitter', 'fb_yt', 'convAI', 'wikipedia',]\\n\\ndf_ori.to_csv(f'Generated_Data/Detox_Pred_DataFrame/{file}', index=False,)# columns=columns)\\n\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "df_all_test = pd.read_csv(\"Datasets/ParaDetox/test/ParaDetox_test.csv\")\n",
    "\n",
    "prefix = 'transfer: '\n",
    "\n",
    "\n",
    "sources = df_all_test['toxic'].tolist()\n",
    "references = df_all_test['non_toxic'].tolist()\n",
    "\n",
    "toxic_list = []\n",
    "for ss in sources:\n",
    "    toxic_list.append(prefix+ss)\n",
    "    \n",
    "responses = model(toxic_list, max_length = 512, truncation=True)\n",
    "\n",
    "model_pred = []\n",
    "for res in responses:\n",
    "    model_pred.append(res['generated_text'])\n",
    "predictions = model_pred\n",
    "\n",
    "\n",
    "output_prediction_file = os.path.join(\"Output_Dir/ParaDetox_Test_Prediction\", \"t5_prefix_paradetox_predictions.jsonl\")\n",
    "\n",
    "with open(output_prediction_file, \"w\") as writer:             \n",
    "    for src, ref, pred in zip(sources, references, predictions):\n",
    "        output = {\n",
    "            'source': src,\n",
    "            'reference': ref,\n",
    "            'prediction': pred,\n",
    "        }\n",
    "        json.dump(output, writer)\n",
    "        #writer.write(\"REFERENCES: \"+str(ref))\n",
    "        #writer.write(\"\\nPREDICTION: \"+str(pred))\n",
    "        writer.write(\"\\n\")\n",
    "\n",
    "\n",
    "'''columns = ['source_text', 'target_text', 'source_label', 'detox_pred', 'platform', 'source_file',\n",
    "   'data_id', 'template', 'toxic_count', 'non_toxic_count', 'HateCheck',\n",
    "   'stormfront', 'twitter', 'fb_yt', 'convAI', 'wikipedia',]\n",
    "\n",
    "df_ori.to_csv(f'Generated_Data/Detox_Pred_DataFrame/{file}', index=False,)# columns=columns)\n",
    "'''\n",
    "#print(f\"TOTAL Ori: {total_ori} ### TOTAL Modified: {total_new}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a14d123-4c74-4f3a-9011-4d59b8a6710f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "model_name = 'Output_Dir/Training_Bart_1/Training_Platform_1/'\n",
    "model = pipeline('text2text-generation', model=model_name, device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "70c1f1e3-dd6b-4b61-8831-9a22ef05ce97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"columns = ['source_text', 'target_text', 'source_label', 'detox_pred', 'platform', 'source_file',\\n   'data_id', 'template', 'toxic_count', 'non_toxic_count', 'HateCheck',\\n   'stormfront', 'twitter', 'fb_yt', 'convAI', 'wikipedia',]\\n\\ndf_ori.to_csv(f'Generated_Data/Detox_Pred_DataFrame/{file}', index=False,)# columns=columns)\\n\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "df_all_test = pd.read_csv(\"Datasets/ParaDetox/test/ParaDetox_test.csv\")\n",
    "\n",
    "prefix = \"Rewrite the following toxic input into non-toxic version:\\n Input: \"\n",
    "\n",
    "\n",
    "sources = df_all_test['toxic'].tolist()\n",
    "references = df_all_test['non_toxic'].tolist()\n",
    "\n",
    "toxic_list = []\n",
    "for ss in sources:\n",
    "    toxic_list.append(prefix+ss)\n",
    "    \n",
    "responses = model(toxic_list, max_length = 512, truncation=True)\n",
    "\n",
    "model_pred = []\n",
    "for res in responses:\n",
    "    model_pred.append(res['generated_text'])\n",
    "predictions = model_pred\n",
    "\n",
    "\n",
    "output_prediction_file = os.path.join(\"Output_Dir/ParaDetox_Test_Prediction\", \"bart_prompt_paradetox_predictions.jsonl\")\n",
    "\n",
    "with open(output_prediction_file, \"w\") as writer:             \n",
    "    for src, ref, pred in zip(sources, references, predictions):\n",
    "        output = {\n",
    "            'source': src,\n",
    "            'reference': ref,\n",
    "            'prediction': pred,\n",
    "        }\n",
    "        json.dump(output, writer)\n",
    "        #writer.write(\"REFERENCES: \"+str(ref))\n",
    "        #writer.write(\"\\nPREDICTION: \"+str(pred))\n",
    "        writer.write(\"\\n\")\n",
    "\n",
    "\n",
    "'''columns = ['source_text', 'target_text', 'source_label', 'detox_pred', 'platform', 'source_file',\n",
    "   'data_id', 'template', 'toxic_count', 'non_toxic_count', 'HateCheck',\n",
    "   'stormfront', 'twitter', 'fb_yt', 'convAI', 'wikipedia',]\n",
    "\n",
    "df_ori.to_csv(f'Generated_Data/Detox_Pred_DataFrame/{file}', index=False,)# columns=columns)\n",
    "'''\n",
    "#print(f\"TOTAL Ori: {total_ori} ### TOTAL Modified: {total_new}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cf3f5890-d4b6-4bbb-9c3b-45f3ff1d390e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "model_name = 'Output_Dir/Training_Bart_No_Prefix_1/Training_Platform_1/'\n",
    "model = pipeline('text2text-generation', model=model_name, device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ce1ef440-2431-4ffc-a87a-30aa8dba9296",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"columns = ['source_text', 'target_text', 'source_label', 'detox_pred', 'platform', 'source_file',\\n   'data_id', 'template', 'toxic_count', 'non_toxic_count', 'HateCheck',\\n   'stormfront', 'twitter', 'fb_yt', 'convAI', 'wikipedia',]\\n\\ndf_ori.to_csv(f'Generated_Data/Detox_Pred_DataFrame/{file}', index=False,)# columns=columns)\\n\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "df_all_test = pd.read_csv(\"Datasets/ParaDetox/test/ParaDetox_test.csv\")\n",
    "\n",
    "prefix = ''\n",
    "\n",
    "\n",
    "sources = df_all_test['toxic'].tolist()\n",
    "references = df_all_test['non_toxic'].tolist()\n",
    "\n",
    "toxic_list = []\n",
    "for ss in sources:\n",
    "    toxic_list.append(prefix+ss)\n",
    "    \n",
    "responses = model(toxic_list, max_length = 512, truncation=True)\n",
    "\n",
    "model_pred = []\n",
    "for res in responses:\n",
    "    model_pred.append(res['generated_text'])\n",
    "predictions = model_pred\n",
    "\n",
    "\n",
    "output_prediction_file = os.path.join(\"Output_Dir/ParaDetox_Test_Prediction\", \"bart_no_prompt_paradetox_predictions.jsonl\")\n",
    "\n",
    "with open(output_prediction_file, \"w\") as writer:             \n",
    "    for src, ref, pred in zip(sources, references, predictions):\n",
    "        output = {\n",
    "            'source': src,\n",
    "            'reference': ref,\n",
    "            'prediction': pred,\n",
    "        }\n",
    "        json.dump(output, writer)\n",
    "        #writer.write(\"REFERENCES: \"+str(ref))\n",
    "        #writer.write(\"\\nPREDICTION: \"+str(pred))\n",
    "        writer.write(\"\\n\")\n",
    "\n",
    "\n",
    "'''columns = ['source_text', 'target_text', 'source_label', 'detox_pred', 'platform', 'source_file',\n",
    "   'data_id', 'template', 'toxic_count', 'non_toxic_count', 'HateCheck',\n",
    "   'stormfront', 'twitter', 'fb_yt', 'convAI', 'wikipedia',]\n",
    "\n",
    "df_ori.to_csv(f'Generated_Data/Detox_Pred_DataFrame/{file}', index=False,)# columns=columns)\n",
    "'''\n",
    "#print(f\"TOTAL Ori: {total_ori} ### TOTAL Modified: {total_new}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "716c6434-5614-41f4-ba73-bee81dbad628",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"columns = ['source_text', 'target_text', 'source_label', 'detox_pred', 'platform', 'source_file',\\n   'data_id', 'template', 'toxic_count', 'non_toxic_count', 'HateCheck',\\n   'stormfront', 'twitter', 'fb_yt', 'convAI', 'wikipedia',]\\n\\ndf_ori.to_csv(f'Generated_Data/Detox_Pred_DataFrame/{file}', index=False,)# columns=columns)\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "df_platform_test = pd.read_csv('Datasets/Toxicity_Specific_Platform_3K/test/test_Specific_Platform_3K.csv')\n",
    "\n",
    "\n",
    "toxic_list = sources = df_platform_test['toxic'].tolist()\n",
    "references = df_platform_test['non_toxic'].tolist()\n",
    "responses = model(toxic_list, max_length = 512, truncation=True)\n",
    "\n",
    "bart_pred = []\n",
    "for res in responses:\n",
    "    bart_pred.append(res['generated_text'])\n",
    "predictions = bart_pred\n",
    "\n",
    "\n",
    "output_prediction_file = os.path.join(\"Output_Dir/ParaDetox_Bart_Prediction\", \"platform_generated_predictions.jsonl\")\n",
    "\n",
    "with open(output_prediction_file, \"w\") as writer:             \n",
    "    for src, ref, pred in zip(sources, references, predictions):\n",
    "        output = {\n",
    "            'source': src,\n",
    "            'reference': ref,\n",
    "            'prediction': pred,\n",
    "        }\n",
    "        json.dump(output, writer)\n",
    "        #writer.write(\"REFERENCES: \"+str(ref))\n",
    "        #writer.write(\"\\nPREDICTION: \"+str(pred))\n",
    "        writer.write(\"\\n\")\n",
    "\n",
    "\n",
    "'''columns = ['source_text', 'target_text', 'source_label', 'detox_pred', 'platform', 'source_file',\n",
    "   'data_id', 'template', 'toxic_count', 'non_toxic_count', 'HateCheck',\n",
    "   'stormfront', 'twitter', 'fb_yt', 'convAI', 'wikipedia',]\n",
    "\n",
    "df_ori.to_csv(f'Generated_Data/Detox_Pred_DataFrame/{file}', index=False,)# columns=columns)\n",
    "'''\n",
    "#print(f\"TOTAL Ori: {total_ori} ### TOTAL Modified: {total_new}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74c5fab-ec2a-4475-bc5a-8a21c4592d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "df_platform_test = pd.read_csv('Datasets/Toxicity_Specific_Platform_3K/test/test_Specific_Platform_3K.csv')\n",
    "\n",
    "\n",
    "toxic_list = sources = df_platform_test['toxic'].tolist()\n",
    "references = df_platform_test['non_toxic'].tolist()\n",
    "responses = model(toxic_list, max_length = 512, truncation=True)\n",
    "\n",
    "bart_pred = []\n",
    "for res in responses:\n",
    "    bart_pred.append(res['generated_text'])\n",
    "predictions = bart_pred\n",
    "\n",
    "\n",
    "output_prediction_file = os.path.join(\"Output_Dir/ParaDetox_Bart_Prediction\", \"platform_generated_predictions.jsonl\")\n",
    "\n",
    "with open(output_prediction_file, \"w\") as writer:             \n",
    "    for src, ref, pred in zip(sources, references, predictions):\n",
    "        output = {\n",
    "            'source': src,\n",
    "            'reference': ref,\n",
    "            'prediction': pred,\n",
    "        }\n",
    "        json.dump(output, writer)\n",
    "        #writer.write(\"REFERENCES: \"+str(ref))\n",
    "        #writer.write(\"\\nPREDICTION: \"+str(pred))\n",
    "        writer.write(\"\\n\")\n",
    "\n",
    "\n",
    "'''columns = ['source_text', 'target_text', 'source_label', 'detox_pred', 'platform', 'source_file',\n",
    "   'data_id', 'template', 'toxic_count', 'non_toxic_count', 'HateCheck',\n",
    "   'stormfront', 'twitter', 'fb_yt', 'convAI', 'wikipedia',]\n",
    "\n",
    "df_ori.to_csv(f'Generated_Data/Detox_Pred_DataFrame/{file}', index=False,)# columns=columns)\n",
    "'''\n",
    "#print(f\"TOTAL Ori: {total_ori} ### TOTAL Modified: {total_new}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
